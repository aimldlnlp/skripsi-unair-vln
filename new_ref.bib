% file: new_ref.bib

@inproceedings{anderson2018r2r,
  author    = {Peter Anderson and Qi Wu and Damien Teney and Jake Bruce and Mark Johnson and Niko S{\"u}nderhauf and Ian Reid and Stephen Gould and Anton van den Hengel},
  title     = {Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  pages     = {3674--3683},
  url       = {https://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.html}
}

@inproceedings{ku2020rxr,
    title = "Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding",
    author = "Ku, Alexander  and
      Anderson, Peter  and
      Patel, Roma  and
      Ie, Eugene  and
      Baldridge, Jason",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.356/",
    doi = "10.18653/v1/2020.emnlp-main.356",
    pages = "4392--4412",
    abstract = "We introduce Room-Across-Room (RxR), a new Vision-and-Language Navigation (VLN) dataset. RxR is multilingual (English, Hindi, and Telugu) and larger (more paths and instructions) than other VLN datasets. It emphasizes the role of language in VLN by addressing known biases in paths and eliciting more references to visible entities. Furthermore, each word in an instruction is time-aligned to the virtual poses of instruction creators and validators. We establish baseline scores for monolingual and multilingual settings and multitask learning when including Room-to-Room annotations (Anderson et al., 2018). We also provide results for a model that learns from synchronized pose traces by focusing only on portions of the panorama attended to in human demonstrations. The size, scope and detail of RxR dramatically expands the frontier for research on embodied language agents in photorealistic simulated environments."
}

@article{liu2025visualgrounding,
  author={Liu, Daizong and Liu, Yang and Huang, Wencan and Hu, Wei},
  title={A survey on text-guided 3D visual grounding: Elements, recent advances, and future directions},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2025},
  volume={36},
  number={10},
  pages={17717-17737},
  doi={10.1109/TNNLS.2025.3584895},
}

@inproceedings{kargaran2024masklid,
    title = "{M}ask{LID}: Code-Switching Language Identification through Iterative Masking",
    author = "Kargaran, Amir Hossein  and
      Yvon, Fran{\c{c}}ois  and
      Schuetze, Hinrich",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-short.43/",
    doi = "10.18653/v1/2024.acl-short.43",
    pages = "459--469",
    abstract = "We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single labels, typically using a softmax layer to turn scores into probabilities. However, in cases where a sentence is composed in both L1 and L2 languages, the LID classifier often only returns the dominant label L1. To address this limitation, MaskLID employs a strategy to mask text features associated with L1, allowing the LID to classify the text as L2 in the next round. This method uses the LID itself to identify the features that require masking and does not rely on any external resource. In this work, we explore the use of MaskLID for two open-source LIDs (GlotLID and OpenLID), that are both based on the FastText architecture. Code and demo are available at https://github.com/cisnlp/MaskLID."
}

@inproceedings{dogruoz-survey,
    title = "A Survey of Code-switching: Linguistic and Social Perspectives for Language Technologies",
    author = {Do{\u{g}}ru{\"o}z, A. Seza  and
      Sitaram, Sunayana  and
      Bullock, Barbara E.  and
      Toribio, Almeida Jacqueline},
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.131/",
    doi = "10.18653/v1/2021.acl-long.131",
    pages = "1654--1666",
    abstract = "The analysis of data in which multiple languages are represented has gained popularity among computational linguists in recent years. So far, much of this research focuses mainly on the improvement of computational methods and largely ignores linguistic and social aspects of C-S discussed across a wide range of languages within the long-established literature in linguistics. To fill this gap, we offer a survey of code-switching (C-S) covering the literature in linguistics with a reflection on the key issues in language technologies. From the linguistic perspective, we provide an overview of structural and functional patterns of C-S focusing on the literature from European and Indian contexts as highly multilingual areas. From the language technologies perspective, we discuss how massive language models fail to represent diverse C-S types due to lack of appropriate training data, lack of robust evaluation benchmarks for C-S (across multilingual situations and types of C-S) and lack of end-to- end systems that cover sociolinguistic aspects of C-S as well. Our survey will be a step to- wards an outcome of mutual benefit for computational scientists and linguists with a shared interest in multilingualism and C-S."
}

@inproceedings{dhawan2023unified,
    title = "Unified Model for Code-Switching Speech Recognition and Language Identification Based on Concatenated Tokenizer",
    author = "Dhawan, Kunal  and
      Rekesh, KDimating  and
      Ginsburg, Boris",
    editor = "Winata, Genta  and
      Kar, Sudipta  and
      Zhukova, Marina  and
      Solorio, Thamar  and
      Diab, Mona  and
      Sitaram, Sunayana  and
      Choudhury, Monojit  and
      Bali, Kalika",
    booktitle = "Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.calcs-1.7/",
    pages = "74--82",
    abstract = "Code-Switching (CS) multilingual Automatic Speech Recognition (ASR) models can transcribe speech containing two or more alternating languages during a conversation. This paper proposes (1) a new method for creating code-switching ASR datasets from purely monolingual data sources, and (2) a novel Concatenated Tokenizer that enables ASR models to generate language ID for each emitted text token while reusing existing monolingual tokenizers. The efficacy of these approaches for building CS ASR models is demonstrated for two language pairs, English-Hindi and English-Spanish, where we achieve new state-of-the-art results on the Miami Bangor CS evaluation corpus. In addition to competitive ASR performance, the proposed Concatenated Tokenizer models are highly effective for spoken language identification, achieving 98{\%}+ accuracy on the out-of-distribution FLEURS dataset."
}

@inproceedings{savva2019habitat,
  author = {Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and Parikh, Devi and Batra, Dhruv},
  title = {Habitat: A Platform for Embodied AI Research},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month = {October},
  year = {2019}
}

@inproceedings{wijmans2020vlnce,
  author= {Erik Wijmans and Abhishek Kadian and Ari S. Morcos and Stefan Lee and Irfan Essa and Devi Parikh and Dhruv Batra and Oleksandr Maksymets},
  title= {Vision-and-Language Navigation in Continuous Environments},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year= {2020},
  pages= {1643--1653},
  url= {https://openaccess.thecvf.com/content_CVPR_2020/html/Wijmans_Vision-and-Language_Navigation_in_Continuous_Environments_CVPR_2020_paper.html}
}

@inproceedings{KrantzVLNCE,
  author = {Krantz, Jacob and Wijmans, Erik and Majumdar, Arjun and Batra, Dhruv and Lee, Stefan},
  title = {Beyond the Nav-Graph: Vision-and-Language Navigation in Continuous Environments},
  year = {2020},
  isbn = {978-3-030-58603-4},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  url = {https://doi.org/10.1007/978-3-030-58604-1_7},
  doi = {10.1007/978-3-030-58604-1_7},
  abstract = {We develop a language-guided navigation task set in a continuous 3D environment where agents must execute low-level actions to follow natural language navigation directions. By being situated in continuous environments, this setting lifts a number of assumptions implicit in prior work that represents environments as a sparse graph of panoramas with edges corresponding to navigability. Specifically, our setting drops the presumptions of known environment topologies, short-range oracle navigation, and perfect agent localization. To contextualize this new task, we develop models that mirror many of the advances made in prior settings as well as single-modality baselines. While some transfer, we find significantly lower absolute performance in the continuous setting – suggesting that performance in prior ‘navigation-graph’ settings may be inflated by the strong implicit assumptions. Code at  .},
  booktitle = {Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXVIII},
  pages = {104–120},
  numpages = {17},
  keywords = {Embodied agents, Vision-and-Language Navigation},
  location = {Glasgow, United Kingdom}
}

@misc{HM3D2021.2,
  author    = {Santhosh K. Ramakrishnan and Alejandro Rosinol and Abhishek Kadian and others},
  title     = {Habitat--Matterport 3D Dataset ({HM3D})},
  year      = {2021},
  howpublished = {Dataset and Report},
  url       = {https://aihabitat.org/datasets/hm3d}
}

@inproceedings{HM3D2021,
  title={Habitat-Matterport 3D Dataset ({HM}3D): 1000 Large-scale 3D Environments for Embodied {AI}},
  author={Santhosh Kumar Ramakrishnan and Aaron Gokaslan and Erik Wijmans and Oleksandr Maksymets and Alexander Clegg and John M Turner and Eric Undersander and Wojciech Galuba and Andrew Westbury and Angel X Chang and Manolis Savva and Yili Zhao and Dhruv Batra},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021},
  url={https://openreview.net/forum?id=-v4OuqNs5P}
}

@inproceedings{gu2022vision,
    title = "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions",
    author = "Gu, Jing  and
      Stefani, Eliana  and
      Wu, Qi  and
      Thomason, Jesse  and
      Wang, Xin",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.524/",
    doi = "10.18653/v1/2022.acl-long.524",
    pages = "7606--7623",
    abstract = "A long-term goal of AI research is to build intelligent agents that can communicate with humans in natural language, perceive the environment, and perform real-world tasks. Vision-and-Language Navigation (VLN) is a fundamental and interdisciplinary research topic towards this goal, and receives increasing attention from natural language processing, computer vision, robotics, and machine learning communities. In this paper, we review contemporary studies in the emerging field of VLN, covering tasks, evaluation metrics, methods, etc. Through structured analysis of current progress and challenges, we also highlight the limitations of current VLN and opportunities for future work. This paper serves as a thorough reference for the VLN research community."
}

@article{Zhang2024,
  title={Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models},
  author={Yue Zhang and Ziqiao Ma and Jialu Li and Yanyuan Qiao and Zun Wang and Joyce Chai and Qi Wu and Mohit Bansal and Parisa Kordjamshidi},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2024},
  url={https://openreview.net/forum?id=yiqeh2ZYUh},
  note={Survey Certification}
}

@inproceedings{Song2025,
  author    = {Song, Xinshuai and Chen, Weixing and Liu, Yang and Chen, Weikai and Li, Guanbin and Lin, Liang},
  title     = {Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2025},
  pages     = {12078-12088}
}

@inproceedings{Ouyang2022,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 publisher = {Curran Associates, Inc.},
 title = {Training language models to follow instructions with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{wang2023selfinstruct,
    title = "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    author = "Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.754/",
    doi = "10.18653/v1/2023.acl-long.754",
    pages = "13484--13508",
    abstract = "Large ``instruction-tuned'' language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33{\%} absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5{\%} absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning."
}

@article{OpenAI2023,
  author    = {{OpenAI}},
  title     = {GPT-4 Technical Report},
  journal   = {arXiv preprint},
  year      = {2023},
  eprint    = {2303.08774},
  url       = {https://arxiv.org/abs/2303.08774}
}

@article{Touvron2023,
  author    = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and others},
  title     = {L{LaMA}: Open and Efficient Foundation Language Models},
  journal   = {arXiv preprint},
  year      = {2023},
  eprint    = {2302.13971},
  url       = {https://arxiv.org/abs/2302.13971}
}

@article{Kuchemann2025,
  author    = {K{\"u}chemann, Stefan and Avila, Karina E. and Dinc, Yavuz and Hortmann, Chiara and Revenga, Natalia and Ruf, Verena and Stausberg, Niklas and Steinert, Steffen and Fischer, Frank and Fischer, Martin and Kasneci, Enkelejda and Kasneci, Gjergji and Kuhr, Thomas and Kutyniok, Gitta and Malone, Sarah and Sailer, Michael and Schmidt, Albrecht and Stadler, Matthias and Weller, Jochen and Kuhn, Jochen},
  title     = {On opportunities and challenges of large multimodal foundation models in education},
  journal   = {npj Science of Learning},
  year      = {2025},
  volume    = {10},
  number    = {1},
  pages     = {11},
  doi       = {10.1038/s41539-025-00301-w},
  url       = {https://doi.org/10.1038/s41539-025-00301-w}
}

@article{Dubey2024,
  author    = {Abhimanyu Dubey and Ankush Garg and Piyush Patil and Aditi Ahuja and others},
  title     = {The {LLaMA} 3 Herd of Models},
  journal   = {arXiv preprint},
  year      = {2024},
  eprint    = {2407.21783},
  url       = {https://arxiv.org/abs/2407.21783}
}

@article{Mienye2025LargeLanguageModels,
  author  = {Mienye, Ibomoiye Domor and Jere, Nobert and Obaido, George and Ogunruku, Oyindamola Omolara and Esenogho, Ebenezer and Modisane, Cameron},
  title   = {Large language models: an overview of foundational architectures, recent trends, and a new taxonomy},
  journal = {Discover Applied Sciences},
  year    = {2025},
  volume  = {7},
  number  = {9},
  pages   = {1027},
  doi     = {10.1007/s42452-025-07668-w},
  url     = {https://doi.org/10.1007/s42452-025-07668-w},
  issn    = {3004-9261},
  date    = {2025-09-02}
}

@article{zhang25llm,
    author = {Zhang, Tianyi and Ladhak, Faisal and Durmus, Esin and Liang, Percy and McKeown, Kathleen and Hashimoto, Tatsunori B.},
    title = {Benchmarking Large Language Models for News Summarization},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {12},
    pages = {39-57},
    year = {2024},
    month = {01},
    abstract = {Large language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we find instruction tuning, not model size, is the key to the LLM’s zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and finetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we find that LLM summaries are judged to be on par with human written summaries.},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00632},
    url = {https://doi.org/10.1162/tacl_a_00632},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00632/2325685/tacl_a_00632.pdf},
}

@article{li24llmtextgen,
author = {Li, Junyi and Tang, Tianyi and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
title = {Pre-Trained Language Models for Text Generation: A Survey},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3649449},
doi = {10.1145/3649449},
abstract = {Text Generation aims to produce plausible and readable text in human language from input data. The resurgence of deep learning has greatly advanced this field, in particular, with the help of neural generation models based on pre-trained language models (PLMs). Text generation based on PLMs is viewed as a promising approach in both academia and industry. In this article, we provide a survey on the utilization of PLMs in text generation. We begin with introducing two key aspects of applying PLMs to text generation: (1) how to design an effective PLM to serve as the generation model; and (2) how to effectively optimize PLMs given the reference text and to ensure that the generated texts satisfy special text properties. Then, we show the major challenges that have arisen in these aspects, as well as possible solutions for them. We also include a summary of various useful resources and typical text generation applications based on PLMs. Finally, we highlight the future research directions which will further improve these PLMs for text generation. This comprehensive survey is intended to help researchers interested in text generation problems to learn the core concepts, the main techniques and the latest developments in this area based on PLMs.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {230},
numpages = {39},
keywords = {Pre-trained language models, natural language processing}
}

@inproceedings{Liu2023a,
 author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {34892--34916},
 publisher = {Curran Associates, Inc.},
 title = {Visual Instruction Tuning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/6dcf277ea32ce3288914faf369fe6de0-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@inproceedings{Zheng2023,
 author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {46595--46623},
 publisher = {Curran Associates, Inc.},
 title = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf},
 volume = {36},
 year = {2023}
}

@inproceedings{Ahn2022,
  title       = {Do As I Can, Not As I Say: Grounding Language in Robotic Affordances},
  author      = {Ahn, Michael and Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and Kalashnikov, Dmitry and Levine, Sergey and Lu, Yao and Parada, Carolina and Rao, Kanishka and Sermanet, Pierre and Toshev, Alexander T. and Vanhoucke, Vincent and Xia, Fei and Xiao, Ted and Xu, Peng and Yan, Mengyuan and Brown, Noah and Cortes, Omar and Sievers, Nicolas and Tan, Clayton and Xu, Sichun and Reyes, Diego and Rettinghouse, Jarek and Quiambao, Jornell and Pastor, Peter and Luu, Linda and Lee, Kuang-Huei and Kuang, Yuheng and Jesmonth, Sally and Joshi, Nikhil J. and Jeffrey, Kyle and Ruano, Rosario Jauregui and Hsu, Jasmine and Gopalakrishnan, Keerthana and David, Byron and Zeng, Andy and Fu, Chuyuan Kelly and Ichter, Brian},
  booktitle   = {Proceedings of The 6th Conference on Robot Learning},
  editor      = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
  series      = {Proceedings of Machine Learning Research},
  volume      = {205},
  pages       = {287--318},
  year        = {2023},
  month       = {December 14--18},
  publisher   = {PMLR},
  pdf         = {https://proceedings.mlr.press/v205/ichter23a/ichter23a.pdf},
  url         = {https://proceedings.mlr.press/v205/ichter23a.html},
  abstract    = {Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, video, and open source can be found at say-can.github.io.}
}

@inproceedings{Brohan2023,
  title        = {RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control},
  author       = {Zitkovich, Brianna and Yu, Tianhe and Xu, Sichun and Xu, Peng and Xiao, Ted and Xia, Fei and Wu, Jialin and Wohlhart, Paul and Welker, Stefan and Wahid, Ayzaan and Vuong, Quan and Vanhoucke, Vincent and Tran, Huong and Soricut, Radu and Singh, Anikait and Singh, Jaspiar and Sermanet, Pierre and Sanketi, Pannag R. and Salazar, Grecia and Ryoo, Michael S. and Reymann, Krista and Rao, Kanishka and Pertsch, Karl and Mordatch, Igor and Michalewski, Henryk and Lu, Yao and Levine, Sergey and Lee, Lisa and Lee, Tsang-Wei Edward and Leal, Isabel and Kuang, Yuheng and Kalashnikov, Dmitry and Julian, Ryan and Joshi, Nikhil J. and Irpan, Alex and Ichter, Brian and Hsu, Jasmine and Herzog, Alexander and Hausman, Karol and Gopalakrishnan, Keerthana and Fu, Chuyuan and Florence, Pete and Finn, Chelsea and Dubey, Kumar Avinava and Driess, Danny and Ding, Tianli and Choromanski, Krzysztof Marcin and Chen, Xi and Chebotar, Yevgen and Carbajal, Justice and Brown, Noah and Brohan, Anthony and Gonzalez Arenas, Montserrat and Han, Kehang},
  booktitle    = {Proceedings of The 7th Conference on Robot Learning (CoRL 2023)},
  editor       = {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  series       = {Proceedings of Machine Learning Research},
  volume       = {229},
  pages        = {2165--2183},
  year         = {2023},
  month        = {November},
  publisher    = {PMLR},
  url          = {https://proceedings.mlr.press/v229/zitkovich23a.html},
  pdf          = {https://proceedings.mlr.press/v229/zitkovich23a/zitkovich23a.pdf},
  abstract     = {We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of thought reasoning allows RT-2 to perform multi-stage semantic reasoning, for example figuring out which object to pick up for use as an improvised hammer (a rock), or which type of drink is best suited for someone who is tired (an energy drink).}
}

@article{liu2024embodiedai,
  author = {Liu, Huaping and Guo, Di and Cangelosi, Angelo},
  title = {Embodied Intelligence: A Synergy of Morphology, Action, Perception and Learning},
  year = {2025},
  issue_date = {July 2025},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {57},
  number = {7},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3717059},
  doi = {10.1145/3717059},
  abstract = {Embodied intelligence emphasizes that the intelligence is affected by the tight coupling of brain, body, and environment. It is continuously and dynamically generated through the process of information perception and physical interaction with the environment. During the past years, the research scope of embodied intelligence has also been expanding and has attracted great attention from various communities. At the same time, a huge number of works relevant to embodied intelligence have been proposed, especially in recent years. In this article, we present a comprehensive survey of embodied intelligence from the perspective that it is a synergy of morphology, action, perception, and learning, providing a thorough summary and categorization of existing studies. Specifically, as embodied intelligence is a synergy of all these components rather than themselves alone, we mainly focus on the connections across these four components (morphology, action, perception, and learning) and identify areas where future research can benefit from their intrinsic connections.},
  journal = {ACM Comput. Surv.},
  month = mar,
  articleno = {186},
  numpages = {36},
  keywords = {Embodied intelligence, morphology, action, perception, learning}
}

@inproceedings{adilazuarda-2022-indorobusta,
    title = "{I}ndo{R}obusta: Towards Robustness Against Diverse Code-Mixed {I}ndonesian Local Languages",
    author = "Adilazuarda, Muhammad Farid  and
      Cahyawijaya, Samuel  and
      Winata, Genta Indra  and
      Fung, Pascale  and
      Purwarianti, Ayu",
    editor = "Ahuja, Kabir  and
      Anastasopoulos, Antonios  and
      Patra, Barun  and
      Neubig, Graham  and
      Choudhury, Monojit  and
      Dandapat, Sandipan  and
      Sitaram, Sunayana  and
      Chaudhary, Vishrav",
    booktitle = "Proceedings of the First Workshop on Scaling Up Multilingual Evaluation",
    month = nov,
    year = "2022",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.sumeval-1.5/",
    doi = "10.18653/v1/2022.sumeval-1.5",
    pages = "25--34"
}

@inproceedings{Tazakka2024,
    title = "{I}ndonesian-{E}nglish Code-Switching Speech Recognition Using the Machine Speech Chain Based Semi-Supervised Learning",
    author = "Tazakka, Rais Vaza Man  and
      Lestari, Dessi  and
      Purwarianti, Ayu  and
      Tanaya, Dipta  and
      Azizah, Kurniawati  and
      Sakti, Sakriani",
    editor = "Melero, Maite  and
      Sakti, Sakriani  and
      Soria, Claudia",
    booktitle = "Proceedings of the 3rd Annual Meeting of the Special Interest Group on Under-resourced Languages @ LREC-COLING 2024",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.sigul-1.18/",
    pages = "143--148",
    abstract = "Indonesia is home to a diverse linguistic landscape, where individuals seamlessly transition between Indonesian, English, and local dialects in their everyday conversations{---}a phenomenon known as code-switching. Understanding and accommodating this linguistic fluidity is essential, particularly in the development of accurate speech recognition systems. However, tackling code-switching in Indonesian poses a challenge due to the scarcity of paired code-switching data. Thus, this study endeavors to address Indonesian-English code-switching in speech recognition, leveraging unlabeled data and employing a semi-supervised technique known as the machine speech chain. Our findings demonstrate that the machine speech chain method effectively enhances Automatic Speech Recognition (ASR) performance in recognizing code-switching between Indonesian and English, utilizing previously untapped resources of unlabeled data."
}

@inproceedings{Handoyo2024,
  author    = {Ahmad Alfani Handoyo and Chung Tran and Dessi Puji Lestari and Sakriani Sakti},
  title     = {Indonesian-English Code-Switching Speech Synthesizer Utilizing Multilingual STEN-TTS and BERT LID},
  booktitle = {Proceedings of the 2024 27th Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (O-COCOSDA)},
  year      = {2024},
  pages     = {},
  address   = {Hsinchu City, Taiwan},
  publisher = {IEEE},
  doi       = {10.1109/O-COCOSDA64382.2024.10800604},
  isbn      = {},
  issn      = {2163-3479},
  eissn     = {2472-7695},
}

@inproceedings{winata2023decades,
    title = "The Decades Progress on Code-Switching Research in {NLP}: A Systematic Survey on Trends and Challenges",
    author = "Winata, Genta  and
      Aji, Alham Fikri  and
      Yong, Zheng Xin  and
      Solorio, Thamar",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.185/",
    doi = "10.18653/v1/2023.findings-acl.185",
    pages = "2936--2978",
    abstract = "Code-Switching, a common phenomenon in written text and conversation, has been studied over decades by the natural language processing (NLP) research community. Initially, code-switching is intensively explored by leveraging linguistic theories and, currently, more machine-learning oriented approaches to develop models. We introduce a comprehensive systematic survey on code-switching research in natural language processing to understand the progress of the past decades and conceptualize the challenges and tasks on the code-switching topic. Finally, we summarize the trends and findings and conclude with a discussion for future direction and open questions for further investigation."
}

@inproceedings{szot2021habitat2,
 author = {Szot, Andrew and Clegg, Alexander and Undersander, Eric and Wijmans, Erik and Zhao, Yili and Turner, John and Maestre, Noah and Mukadam, Mustafa and Chaplot, Devendra Singh and Maksymets, Oleksandr and Gokaslan, Aaron and Vondru\v{s}, Vladim\'{\i}r and Dharur, Sameer and Meier, Franziska and Galuba, Wojciech and Chang, Angel and Kira, Zsolt and Koltun, Vladlen and Malik, Jitendra and Savva, Manolis and Batra, Dhruv},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {251--266},
 publisher = {Curran Associates, Inc.},
 title = {Habitat 2.0: Training Home Assistants to Rearrange their Habitat},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/021bbc7ee20b71134d53e20206bd6feb-Paper.pdf},
 volume = {34},
 year = {2021}
}

@inproceedings{szot2021habitat2.2,
author = {Szot, Andrew and Clegg, Alex and Undersander, Eric and Wijmans, Erik and Zhao, Yili and Turner, John and Maestre, Noah and Mukadam, Mustafa and Chaplot, Devendra and Maksymets, Oleksandr and Gokaslan, Aaron and Vondrus, Vladimir and Dharur, Sameer and Meier, Franziska and Galuba, Wojciech and Chang, Angel and Kira, Zsolt and Koltun, Vladlen and Malik, Jitendra and Savva, Manolis and Batra, Dhruv},
title = {Habitat 2.0: training home assistants to rearrange their habitat},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce Habitat 2.0 (H2.0), a simulation platform for training virtual robots in interactive 3D environments and complex physics-enabled scenarios. We make comprehensive contributions to all levels of the embodied AI stack – data, simulation, and benchmark tasks. Specifically, we present: (i) ReplicaCAD: an artist-authored, annotated, reconfigurable 3D dataset of apartments (matching real spaces) with articulated objects (e.g. cabinets and drawers that can open/close); (ii) H2.0: a high-performance physics-enabled 3D simulator with speeds exceeding 25,000 simulation steps per second (850\texttimes{} real-time) on an 8-GPU node, representing 100\texttimes{} speed-ups over prior work; and, (iii) Home Assistant Benchmark (HAB): a suite of common tasks for assistive robots (tidy the house, stock groceries, set the table) that test a range of mobile manipulation capabilities. These large-scale engineering contributions allow us to systematically compare deep reinforcement learning (RL) at scale and classical sense-plan-act (SPA) pipelines in long-horizon structured tasks, with an emphasis on generalization to new objects, receptacles, and layouts. We find that (1) flat RL policies struggle on HAB compared to hierarchical ones; (2) a hierarchy with independent skills suffers from 'hand-off problems', and (3) SPA pipelines are more brittle than RL policies.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {20},
numpages = {16},
series = {NIPS '21}
}

@inproceedings{xia2018gibson,
author = {Xia, Fei and Zamir, Amir R. and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
title = {Gibson Env: Real-World Perception for Embodied Agents},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@inproceedings {chang2017matterport3d,
author = { Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niebner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda },
booktitle = { 2017 International Conference on 3D Vision (3DV) },
title = {{ Matterport3D: Learning from RGB-D Data in Indoor Environments }},
year = {2017},
volume = {},
ISSN = {2475-7888},
pages = {667-676},
abstract = { Access to large, diverse RGB-D datasets is critical for training RGB-D scene understanding algorithms. However, existing datasets still cover only a limited number of views or a restricted scale of spaces. In this paper, we introduce Matterport3D, a large-scale RGB-D dataset containing 10,800 panoramic views from 194,400 RGB-D images of 90 building-scale scenes. Annotations are provided with surface reconstructions, camera poses, and 2D and 3D semantic segmentations. The precise global alignment and comprehensive, diverse panoramic set of views over entire buildings enable a variety of supervised and self-supervised computer vision tasks, including keypoint matching, view overlap prediction, normal prediction from color, semantic segmentation, and region classification. },
keywords = {Semantics;Cameras;Buildings;Surface reconstruction;Three-dimensional displays;Task analysis;Image reconstruction},
doi = {10.1109/3DV.2017.00081},
url = {https://doi.ieeecomputersociety.org/10.1109/3DV.2017.00081},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Oct}

@InProceedings{qi2020reverie,
author = {Qi, Yuankai and Wu, Qi and Anderson, Peter and Wang, Xin and Wang, William Yang and Shen, Chunhua and Hengel, Anton van den},
title = {REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}


@inproceedings{thomason2020cvdn,
  title = 	 {Vision-and-Dialog Navigation},
  author =       {Thomason, Jesse and Murray, Michael and Cakmak, Maya and Zettlemoyer, Luke},
  booktitle = 	 {Proceedings of the Conference on Robot Learning},
  pages = 	 {394--406},
  year = 	 {2020},
  editor = 	 {Kaelbling, Leslie Pack and Kragic, Danica and Sugiura, Komei},
  volume = 	 {100},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {30 Oct--01 Nov},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v100/thomason20a/thomason20a.pdf},
  url = 	 {https://proceedings.mlr.press/v100/thomason20a.html},
  abstract = 	 {Robots navigating in human environments should use language to ask for assistance and be able to understand human responses. To study this challenge, we introduce Cooperative Vision-and-Dialog Navigation, a dataset of over 2k embodied, human-human dialogs situated in simulated, photorealistic home environments. The Navigator asks questions to their partner, the Oracle, who has privileged access to the best next steps the Navigator should take according to a shortest path planner. To train agents that search an environment for a goal location, we define the Navigation from Dialog History task. An agent, given a target object and a dialog history between humans cooperating to find that object, must infer navigation actions towards the goal in unexplored environments. We establish an initial, multi-modal sequence-to-sequence model and demonstrate that looking farther back in the dialog history improves performance. Sourcecode and a live interface demo can be found at https://cvdn.dev/}
}

@InProceedings{chen2019touchdown,
author = {Chen, Howard and Suhr, Alane and Misra, Dipendra and Snavely, Noah and Artzi, Yoav},
title = {TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@inproceedings{fried2018speaker,
 author = {Fried, Daniel and Hu, Ronghang and Cirik, Volkan and Rohrbach, Anna and Andreas, Jacob and Morency, Louis-Philippe and Berg-Kirkpatrick, Taylor and Saenko, Kate and Klein, Dan and Darrell, Trevor},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Speaker-Follower Models for Vision-and-Language Navigation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/6a81681a7af700c6385d36577ebec359-Paper.pdf},
 volume = {31},
 year = {2018}
}

@inproceedings{kimrlif,
 author = {Luo, Jianlan and Dong, Perry and Zhai, Yuexiang and Ma, Yi and Levine, Sergey},
 booktitle = {International Conference on Representation Learning},
 editor = {B. Kim and Y. Yue and S. Chaudhuri and K. Fragkiadaki and M. Khan and Y. Sun},
 pages = {36329--36351},
 title = {RLIF: Interactive Imitation Learning as Reinforcement Learning},
 url = {https://proceedings.iclr.cc/paper_files/paper/2024/file/9c537882044c8b5352c363e840872ddb-Paper-Conference.pdf},
 volume = {2024},
 year = {2024}
}

@inproceedings{koyejo2022,
 author = {Mei, Jincheng and Chung, Wesley and Thomas, Valentin and Dai, Bo and Szepesvari, Csaba and Schuurmans, Dale},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {17818--17830},
 publisher = {Curran Associates, Inc.},
 title = {The Role of Baselines in Policy Gradient Optimization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/718d02a76d69686a36eccc8cde3e6a41-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{radford2021clip,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8748--8763},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/radford21a.html},
  abstract = 	 {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.}
}

@inproceedings{Lu2023PlanSolve,
    title = "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models",
    author = "Wang, Lei  and
      Xu, Wanyu  and
      Lan, Yihuai  and
      Hu, Zhiqiang  and
      Lan, Yunshi  and
      Lee, Roy Ka-Wei  and
      Lim, Ee-Peng",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.147/",
    doi = "10.18653/v1/2023.acl-long.147",
    pages = "2609--2634",
    abstract = "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, Few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual efforts, Zero-shot-CoT concatenates the target problem statement with ``\textit{Let{'}s think step by step}'' as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting. We evaluate our proposed prompting strategy on ten datasets across three reasoning problems. The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought Prompting, and has comparable performance with 8-shot CoT prompting on the math reasoning problem. The code can be found at \url{https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting}."
}

@inproceedings{Yao2023ReAct,
title={ReAct: Synergizing Reasoning and Acting in Language Models},
author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=WE_vluYUL-X}
}

@inproceedings{Liu2023GEval,
    title = "{G}-Eval: {NLG} Evaluation using Gpt-4 with Better Human Alignment",
    author = "Liu, Yang  and
      Iter, Dan  and
      Xu, Yichong  and
      Wang, Shuohang  and
      Xu, Ruochen  and
      Zhu, Chenguang",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.153/",
    doi = "10.18653/v1/2023.emnlp-main.153",
    pages = "2511--2522",
    abstract = "The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present G-Eval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that G-Eval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperforming all previous methods by a large margin. We also propose analysis on the behavior of LLM-based evaluators, and highlight the potential concern of LLM-based evaluators having a bias towards the LLM-generated texts."
}

@inproceedings{Geng2023GCD,
    title = "Grammar-Constrained Decoding for Structured {NLP} Tasks without Finetuning",
    author = "Geng, Saibo  and
      Josifoski, Martin  and
      Peyrard, Maxime  and
      West, Robert",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.674/",
    doi = "10.18653/v1/2023.emnlp-main.674",
    pages = "10932--10952",
    abstract = "Despite their impressive performance, large language models (LMs) still struggle with reliably generating complex output structures when not finetuned to follow the required output format exactly. To address this issue, grammar-constrained decoding (GCD) can be used to control the generation of LMs, guaranteeing that the output follows a given structure. Most existing GCD methods are, however, limited to specific tasks, such as parsing or code generation. In this work, we demonstrate that formal grammars can describe the output space for a much wider range of tasks and argue that GCD can serve as a unified framework for structured NLP tasks in general. For increased flexibility, we introduce input-dependent grammars, which allow the grammar to depend on the input and thus enable the generation of different output structures for different inputs. We then empirically demonstrate the power and flexibility of GCD-enhanced LMs on (1) information extraction, (2) entity disambiguation, and (3) constituency parsing. Our results indicate that grammar-constrained LMs substantially outperform unconstrained LMs or even beat task-specific finetuned models. Grammar constraints thus hold great promise for harnessing off-the-shelf LMs for a wide range of structured NLP tasks, especially where training data is scarce or finetuning is expensive. Code and data: https://github.com/epfl-dlab/GCD."
}

@misc{Willard2023Outlines,
      title={Efficient Guided Generation for Large Language Models}, 
      author={Brandon T. Willard and Rémi Louf},
      year={2023},
      eprint={2307.09702},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09702}, 
}

@inproceedings{BeurerKellner2024Domino,
author = {Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin},
title = {Guiding LLMs the right way: fast, non-invasive constrained generation},
year = {2024},
publisher = {JMLR.org},
abstract = {To ensure that text generated by large language models (LLMs) is in an expected format, constrained decoding proposes to enforce strict formal language constraints during generation. However, as we show in this work, not only do such methods incur performance overhead during generation, but many of them also significantly impair task accuracy, if they do not correctly align the underlying LLM sub-word vocabularies with external constraints. To address this, we present a novel decoding algorithm, DOMINO, that can enforce constraints in a fully subword-aligned fashion, while leveraging pre-computation and speculative decoding to achieve virtually no overhead and in some cases even almost 2\texttimes{} speedup over unconstrained decoding - thereby outperforming existing approaches by a wide margin. We release DOMINO as open source on GitHub.},
booktitle = {Proceedings of the 41st International Conference on Machine Learning},
articleno = {146},
numpages = {16},
location = {Vienna, Austria},
series = {ICML'24}
}

@inproceedings{Koo2024AutomataConstraints,
  title={Automata-based constraints for language model decoding},
  author={Terry Koo and Frederick Liu and Luheng He},
  booktitle={First Conference on Language Modeling},
  year={2024},
  url={https://openreview.net/forum?id=BDBdblmyzY}
}

@inproceedings{Park2025FlexibleGCD,
  title={Flexible and Efficient Grammar-Constrained Decoding},
  author={Kanghee Park and Timothy Zhou and Loris D'Antoni},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025},
  url={https://openreview.net/forum?id=L6CYAzpO1k}
}

@inproceedings{Raspanti2025GCDIndustry,
    title = "Grammar-Constrained Decoding Makes Large Language Models Better Logical Parsers",
    author = "Raspanti, Federico  and
      Ozcelebi, Tanir  and
      Holenderski, Mike",
    editor = "Rehm, Georg  and
      Li, Yunyao",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 6: Industry Track)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-industry.34/",
    doi = "10.18653/v1/2025.acl-industry.34",
    pages = "485--499",
    ISBN = "979-8-89176-288-6",
    abstract = "Large Language Models (LLMs) have shown capabilities in various natural language processing tasks, yet they often struggle with logical reasoning, particularly when dealing with complex natural language statements. To address this challenge, approaches that combine LLMs with symbolic reasoners have been proposed, where the LLM translates the natural language statements into symbolic representations, which are then verified by an external symbolic solver. However, ensuring syntactic correctness in these translations remains a significant challenge. To address this, we propose to constrain the outputs of the LLMs using Grammar-Constrained Decoding, showing that it consistently improves both syntactic correctness and semantic accuracy in logical parsing tasks. Our findings suggest that grammar constraints can serve as an effective substitute for in-context examples, especially beneficial for resource-constrained applications using smaller models."
}

@inproceedings{Chi2024TIndex,
  title     = {{Characterizing code-switching: Applying Linguistic Principles for Metric Assessment and Development}},
  author    = {Jie Chi and Electra Wallington and Peter Bell},
  year      = {2024},
  booktitle = {{Interspeech 2024}},
  pages     = {7--11},
  doi       = {10.21437/Interspeech.2024-551},
  issn      = {2958-1796},
}

@inproceedings{SrivastavaSingh2021CALCS,
    title = "Challenges and Limitations with the Metrics Measuring the Complexity of Code-Mixed Text",
    author = "Srivastava, Vivek  and
      Singh, Mayank",
    editor = "Solorio, Thamar  and
      Chen, Shuguang  and
      Black, Alan W.  and
      Diab, Mona  and
      Sitaram, Sunayana  and
      Soto, Victor  and
      Yilmaz, Emre  and
      Srinivasan, Anirudh",
    booktitle = "Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.calcs-1.2/",
    doi = "10.18653/v1/2021.calcs-1.2",
    pages = "6--14",
    abstract = "Code-mixing is a frequent communication style among multilingual speakers where they mix words and phrases from two different languages in the same utterance of text or speech. Identifying and filtering code-mixed text is a challenging task due to its co-existence with monolingual and noisy text. Over the years, several code-mixing metrics have been extensively used to identify and validate code-mixed text quality. This paper demonstrates several inherent limitations of code-mixing metrics with examples from the already existing datasets that are popularly used across various experiments."
}

@inproceedings{Suresh2025CSSum,
    title = "{CS}-Sum: A Benchmark for Code-Switching Dialogue Summarization and the Limits of Large Language Models",
    author = "Suresh, Sathya Krishnan  and
      Surana, Tanmay  and
      Hao, Lim Zhi  and
      Chng, Eng Siong",
    editor = "Dong, Yue  and
      Xiao, Wen  and
      Zhang, Haopeng  and
      Zhang, Rui  and
      Ernst, Ori  and
      Wang, Lu  and
      Liu, Fei",
    booktitle = "Proceedings of The 5th New Frontiers in Summarization Workshop",
    month = nov,
    year = "2025",
    address = "Hybrid",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.newsum-main.3/",
    doi = "10.18653/v1/2025.newsum-main.3",
    pages = "31--47",
    ISBN = "979-8-89176-337-1",
    abstract = "Code-switching (CS) poses a significant challenge for Large Language Models (LLMs), yet its comprehensibility remains underexplored in LLMs. We introduce CS-Sum, to evaluate the comprehensibility of CS by the LLMs through CS dialogue to English summarization. CS-Sum is the first benchmark for CS dialogue summarization across Mandarin-English (EN-ZH), Tamil-English (EN-TA), and Malay-English (EN-MS), with 900-1300 human-annotated dialogues per language pair. Evaluating ten LLMs, including open and closed-source models, we analyze performance across few-shot, translate-summarize, and fine-tuning (LoRA, QLoRA on synthetic data) approaches. Our findings show that though the scores on automated metrics are high, LLMs make subtle mistakes that alter the complete meaning of the dialogue. To this end, we introduce 3 most common type of errors that LLMs make when handling CS input. Error rates vary across CS pairs and LLMs, with some LLMs showing more frequent errors on certain language pairs, underscoring the need for specialized training on code-switched data."
}

@article{qwen2,
  publtype={informal},
  author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
  title={Qwen2 Technical Report},
  year={2024},
  cdate={1704067200000},
  journal={CoRR},
  volume={abs/2407.10671},
  url={https://doi.org/10.48550/arXiv.2407.10671}
}

@inproceedings{koto23llm,
    title = "Large Language Models Only Pass Primary School Exams in {I}ndonesia: A Comprehensive Test on {I}ndo{MMLU}",
    author = "Koto, Fajri  and
      Aisyah, Nurul  and
      Li, Haonan  and
      Baldwin, Timothy",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.760/",
    doi = "10.18653/v1/2023.emnlp-main.760",
    pages = "12359--12374",
    abstract = "Although large language models (LLMs) are often pre-trained on large-scale multilingual texts, their reasoning abilities and real-world knowledge are mainly evaluated based on English datasets. Assessing LLM capabilities beyond English is increasingly vital but hindered due to the lack of suitable datasets. In this work, we introduce IndoMMLU, the first multi-task language understanding benchmark for Indonesian culture and languages, which consists of questions from primary school to university entrance exams in Indonesia. By employing professional teachers, we obtain 14,981 questions across 64 tasks and education levels, with 46{\%} of the questions focusing on assessing proficiency in the Indonesian language and knowledge of nine local languages and cultures in Indonesia. Our empirical evaluations show that GPT-3.5 only manages to pass the Indonesian primary school level, with limited knowledge of local Indonesian languages and culture. Other smaller models such as BLOOMZ and Falcon perform at even lower levels."
}

@misc{qwen25,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2025},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115}, 
}

@InProceedings{zhang2023recognize,
    author    = {Zhang, Youcai and Huang, Xinyu and Ma, Jinyu and Li, Zhaoyang and Luo, Zhaochuan and Xie, Yanchun and Qin, Yuzhuo and Luo, Tong and Li, Yaqian and Liu, Shilong and Guo, Yandong and Zhang, Lei},
    title     = {Recognize Anything: A Strong Image Tagging Model},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2024},
    pages     = {1724-1732}
}

@misc{huang2023tag2text,
      title={Tag2Text: Guiding Vision-Language Model via Image Tagging}, 
      author={Xinyu Huang and Youcai Zhang and Jinyu Ma and Weiwei Tian and Rui Feng and Yuejie Zhang and Yaqian Li and Yandong Guo and Lei Zhang},
      year={2024},
      eprint={2303.05657},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.05657}, 
}

@inproceedings{huang2023openset,
    author = {Huang, Xinyu and Huang, Yi-Jie and Zhang, Youcai and Tian, Weiwei and Feng, Rui and Zhang, Yuejie and Xie, Yanchun and Li, Yaqian and Zhang, Lei},
    title = {Open-Set Image Tagging with Multi-Grained Text Supervision},
    year = {2025},
    isbn = {9798400720352},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3746027.3755316},
    doi = {10.1145/3746027.3755316},
    abstract = {This paper introduces the Recognize Anything Plus Model (RAM++), an open-set image tagging model effectively leveraging multi-grained text supervision. Previous approaches (e.g., CLIP) primarily utilize global text supervision paired with images, leading to sub-optimal performance in recognizing multiple individual semantic tags. In contrast, RAM++ seamlessly integrates individual tag supervision with global text supervision, all within a unified alignment framework. This integration not only ensures efficient recognition of predefined tag categories, but also enhances generalization capabilities for diverse open-set categories. Furthermore, RAM++ employs large language models (LLMs) to convert semantically constrained tag supervision into more expansive tag description supervision, thereby enriching the scope of open-set visual description concepts. Comprehensive evaluations on various image recognition benchmarks demonstrate RAM++ exceeds existing state-of-the-art (SOTA) open-set image tagging models on most aspects. Specifically, for predefined commonly used tag categories, RAM++ showcases 10.2 mAP and 15.4 mAP enhancements over CLIP on OpenImages and ImageNet. For open-set categories beyond predefined, RAM++ records improvements of 5.0 mAP and 6.4 mAP over CLIP and RAM respectively on OpenImages. For diverse human-object interaction phrases, RAM++ achieves 7.8 mAP and 4.7 mAP improvements on the HICO benchmark.},
    booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
    pages = {4117–4126},
    numpages = {10},
    keywords = {image understanding, multi-grained supervision, open-set image tagging, vision-language model},
    location = {Dublin, Ireland},
    series = {MM '25}
}

@InProceedings{kirillov2023segment,
    author    = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollar, Piotr and Girshick, Ross},
    title     = {Segment Anything},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {4015-4026}
}

@inproceedings{qlora,
 author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {10088--10115},
 publisher = {Curran Associates, Inc.},
 title = {QLoRA: Efficient Finetuning of Quantized LLMs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/1feb87871436031bdc0f2beaa62a049b-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@inproceedings{nusax,
    title = "{N}usa{X}: Multilingual Parallel Sentiment Dataset for 10 {I}ndonesian Local Languages",
    author = "Winata, Genta Indra  and
      Aji, Alham Fikri  and
      Cahyawijaya, Samuel  and
      Mahendra, Rahmad  and
      Koto, Fajri  and
      Romadhony, Ade  and
      Kurniawan, Kemal  and
      Moeljadi, David  and
      Prasojo, Radityo Eko  and
      Fung, Pascale  and
      Baldwin, Timothy  and
      Lau, Jey Han  and
      Sennrich, Rico  and
      Ruder, Sebastian",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.57/",
    doi = "10.18653/v1/2023.eacl-main.57",
    pages = "815--834",
    abstract = "Natural language processing (NLP) has a significant impact on society via technologies such as machine translation and search engines. Despite its success, NLP technology is only widely available for high-resource languages such as English and Chinese, while it remains inaccessible to many languages due to the unavailability of data resources and benchmarks. In this work, we focus on developing resources for languages in Indonesia. Despite being the second most linguistically diverse country, most languages in Indonesia are categorized as endangered and some are even extinct. We develop the first-ever parallel resource for 10 low-resource languages in Indonesia. Our resource includes sentiment and machine translation datasets, and bilingual lexicons. We provide extensive analyses and describe challenges for creating such resources. We hope this work can spark NLP research on Indonesian and other underrepresented languages."
}

@inproceedings{nusacrowd,
    title = "{N}usa{C}rowd: Open Source Initiative for {I}ndonesian {NLP} Resources",
    author = "Cahyawijaya, Samuel  and
      Lovenia, Holy  and
      Aji, Alham Fikri  and
      Winata, Genta  and
      Wilie, Bryan  and
      Koto, Fajri  and
      Mahendra, Rahmad  and
      Wibisono, Christian  and
      Romadhony, Ade  and
      Vincentio, Karissa  and
      Santoso, Jennifer  and
      Moeljadi, David  and
      Wirawan, Cahya  and
      Hudi, Frederikus  and
      Wicaksono, Muhammad Satrio  and
      Parmonangan, Ivan  and
      Alfina, Ika  and
      Putra, Ilham Firdausi  and
      Rahmadani, Samsul  and
      Oenang, Yulianti  and
      Septiandri, Ali  and
      Jaya, James  and
      Dhole, Kaustubh  and
      Suryani, Arie  and
      Putri, Rifki Afina  and
      Su, Dan  and
      Stevens, Keith  and
      Nityasya, Made Nindyatama  and
      Adilazuarda, Muhammad  and
      Hadiwijaya, Ryan  and
      Diandaru, Ryandito  and
      Yu, Tiezheng  and
      Ghifari, Vito  and
      Dai, Wenliang  and
      Xu, Yan  and
      Damapuspita, Dyah  and
      Wibowo, Haryo  and
      Tho, Cuk  and
      Karo Karo, Ichwanul  and
      Fatyanosa, Tirana  and
      Ji, Ziwei  and
      Neubig, Graham  and
      Baldwin, Timothy  and
      Ruder, Sebastian  and
      Fung, Pascale  and
      Sujaini, Herry  and
      Sakti, Sakriani  and
      Purwarianti, Ayu",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.868/",
    doi = "10.18653/v1/2023.findings-acl.868",
    pages = "13745--13818",
    abstract = "We present NusaCrowd, a collaborative initiative to collect and unify existing resources for Indonesian languages, including opening access to previously non-public resources. Through this initiative, we have brought together 137 datasets and 118 standardized data loaders. The quality of the datasets has been assessed manually and automatically, and their value is demonstrated through multiple experiments.NusaCrowd{'}s data collection enables the creation of the first zero-shot benchmarks for natural language understanding and generation in Indonesian and the local languages of Indonesia. Furthermore, NusaCrowd brings the creation of the first multilingual automatic speech recognition benchmark in Indonesian and the local languages of Indonesia. Our work strives to advance natural language processing (NLP) research for languages that are under-represented despite being widely spoken."
}

@InProceedings{pmlr-v202-dehghani23a,
  title = 	 {Scaling Vision Transformers to 22 Billion Parameters},
  author =       {Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and Jenatton, Rodolphe and Beyer, Lucas and Tschannen, Michael and Arnab, Anurag and Wang, Xiao and Riquelme Ruiz, Carlos and Minderer, Matthias and Puigcerver, Joan and Evci, Utku and Kumar, Manoj and Steenkiste, Sjoerd Van and Elsayed, Gamaleldin Fathy and Mahendran, Aravindh and Yu, Fisher and Oliver, Avital and Huot, Fantine and Bastings, Jasmijn and Collier, Mark and Gritsenko, Alexey A. and Birodkar, Vighnesh and Vasconcelos, Cristina Nader and Tay, Yi and Mensink, Thomas and Kolesnikov, Alexander and Pavetic, Filip and Tran, Dustin and Kipf, Thomas and Lucic, Mario and Zhai, Xiaohua and Keysers, Daniel and Harmsen, Jeremiah J. and Houlsby, Neil},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {7480--7512},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/dehghani23a/dehghani23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/dehghani23a.html},
  abstract = 	 {The scaling of Transformers has driven breakthrough capabilities for language models. At present, the largest large language models (LLMs) contain upwards of 100B parameters. Vision Transformers (ViT) have introduced the same architecture to image and video modelling, but these have not yet been successfully scaled to nearly the same degree; the largest dense ViT contains 4B parameters (Chen et al., 2022). We present a recipe for highly efficient and stable training of a 22B-parameter ViT (ViT-22B) and perform a wide variety of experiments on the resulting model. When evaluated on downstream tasks (often with a lightweight linear model on frozen features), ViT-22B demonstrates increasing performance with scale. We further observe other interesting benefits of scale, including an improved tradeoff between fairness and performance, state-of-the-art alignment to human visual perception in terms of shape/texture bias, and improved robustness. ViT-22B demonstrates the potential for "LLM-like" scaling in vision, and provides key steps towards getting there.}
}

@inproceedings{jain2019stay,
    title = "Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation",
    author = "Jain, Vihan  and
      Magalhaes, Gabriel  and
      Ku, Alexander  and
      Vaswani, Ashish  and
      Ie, Eugene  and
      Baldridge, Jason",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1181/",
    doi = "10.18653/v1/P19-1181",
    pages = "1862--1872",
    abstract = "Advances in learning and representations have reinvigorated work that connects language to other modalities. A particularly exciting direction is Vision-and-Language Navigation(VLN), in which agents interpret natural language instructions and visual scenes to move through environments and reach goals. Despite recent progress, current research leaves unclear how much of a role language under-standing plays in this task, especially because dominant evaluation metrics have focused on goal completion rather than the sequence of actions corresponding to the instructions. Here, we highlight shortcomings of current metrics for the Room-to-Room dataset (Anderson et al.,2018b) and propose a new metric, Coverage weighted by Length Score (CLS). We also show that the existing paths in the dataset are not ideal for evaluating instruction following because they are direct-to-goal shortest paths. We join existing short paths to form more challenging extended paths to create a new data set, Room-for-Room (R4R). Using R4R and CLS, we show that agents that receive rewards for instruction fidelity outperform agents that focus on goal completion."
}

@inproceedings{shridhar2020alfred,
author = {Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
title = {ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@book{muysken2000bilingual,
  author    = {Muysken, Pieter},
  title     = {Bilingual Speech: A Typology of {Code-Mixing}},
  year      = {2000},
  publisher = {Cambridge University Press},
  address   = {Cambridge},
  isbn      = {9780521771689}
}

@article{nabila2022twitter,
  author  = {Nabila, Cindy and Idayani, Andi},
  title   = {An Analysis of Indonesian-English Code Mixing Used in Social Media (Twitter)},
  journal = {J-SHMIC: Journal of English for Academic},
  year    = {2022},
  volume  = {9},
  number  = {1},
  pages   = {1--12},
  doi     = {10.25299/jshmic.2022.vol9(1).9036},
  url     = {https://journal.uir.ac.id/index.php/jshmic/article/view/9036}
}

@article{dewi2021instagram,
  author  = {Dewi, Gusti Putu Rustika and Adnyani, Ni Luh Putu Sri and Padmadewi, Ni Nyoman and Suwastini, Ni Komang Arie and Jayantini, I Gusti Agung Sri Rwa},
  title   = {Indonesian-English Code-Mixing in Instagram Captions of an Indonesian Celebgram},
  journal = {TELL-US Journal},
  year    = {2021},
  volume  = {7},
  number  = {2},
  doi     = {10.22202/tus.2021.v7i2.5101},
  url     = {https://garuda.kemdiktisaintek.go.id/documents/detail/3397632}
}

@article{hidayatullah2023peerj,
  author  = {Hidayatullah, Ahmad Fathan and Apong, Rosyzie Anna and Lai, Daphne T. C. and Qazi, Atika},
  title   = {Corpus creation and language identification for code-mixed Indonesian-Javanese-English Tweets},
  journal = {PeerJ Computer Science},
  year    = {2023},
  volume  = {9},
  pages   = {e1312},
  doi     = {10.7717/peerj-cs.1312},
  url     = {https://pubmed.ncbi.nlm.nih.gov/37409088/}
}

@article{Chiche2022,
  author  = {Chiche, Alebachew and Yitagesu, Betselot},
  title   = {Part of speech tagging: a systematic review of deep learning and machine learning approaches},
  journal = {Journal of Big Data},
  year    = {2022},
  volume  = {9},
  number  = {1},
  pages   = {10},
  doi     = {10.1186/s40537-022-00561-y},
  url     = {https://doi.org/10.1186/s40537-022-00561-y},
  issn    = {2196-1115},
  date    = {2022-01-24}
}

@inproceedings{tarunesh-etal-2021-machine,
    title = "From Machine Translation to Code-Switching: Generating High-Quality Code-Switched Text",
    author = "Tarunesh, Ishan  and
      Kumar, Syamantak  and
      Jyothi, Preethi",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.245/",
    doi = "10.18653/v1/2021.acl-long.245",
    pages = "3154--3169",
    abstract = "Generating code-switched text is a problem of growing interest, especially given the scarcity of corpora containing large volumes of real code-switched text. In this work, we adapt a state-of-the-art neural machine translation model to generate Hindi-English code-switched sentences starting from monolingual Hindi sentences. We outline a carefully designed curriculum of pretraining steps, including the use of synthetic code-switched text, that enable the model to generate high-quality code-switched text. Using text generated from our model as data augmentation, we show significant reductions in perplexity on a language modeling task, compared to using text from other generative models of CS text. We also show improvements using our text for a downstream code-switched natural language inference task. Our generated text is further subjected to a rigorous evaluation using a human evaluation study and a range of objective metrics, where we show performance comparable (and sometimes even superior) to code-switched text obtained via crowd workers who are native Hindi speakers."
}

@inproceedings{gamback-das-2016-comparing,
    title = "Comparing the Level of Code-Switching in Corpora",
    author = {Gamb{\"a}ck, Bj{\"o}rn  and
      Das, Amitava},
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Grobelnik, Marko  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, Helene  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L16-1292/",
    pages = "1850--1855",
    abstract = "Social media texts are often fairly informal and conversational, and when produced by bilinguals tend to be written in several different languages simultaneously, in the same way as conversational speech. The recent availability of large social media corpora has thus also made large-scale code-switched resources available for research. The paper addresses the issues of evaluation and comparison these new corpora entail, by defining an objective measure of corpus level complexity of code-switched texts. It is also shown how this formal measure can be used in practice, by applying it to several code-switched corpora."
}

@inproceedings{barik-etal-2019-normalization,
    title = "Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data",
    author = "Barik, Anab Maulana  and
      Mahendra, Rahmad  and
      Adriani, Mirna",
    editor = "Xu, Wei  and
      Ritter, Alan  and
      Baldwin, Tim  and
      Rahimi, Afshin",
    booktitle = "Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-5554/",
    doi = "10.18653/v1/D19-5554",
    pages = "417--424",
    abstract = "Twitter is an excellent source of data for NLP researches as it offers tremendous amount of textual data. However, processing tweet to extract meaningful information is very challenging, at least for two reasons: (i) using nonstandard words as well as informal writing manner, and (ii) code-mixing issues, which is combining multiple languages in single tweet conversation. Most of the previous works have addressed both issues in isolated different task. In this study, we work on normalization task in code-mixed Twitter data, more specifically in Indonesian-English language. We propose a pipeline that consists of four modules, i.e tokenization, language identification, lexical normalization, and translation. Another contribution is to provide a gold standard of Indonesian-English code-mixed data for each module."
}

@article{Yulianti2021,
title = {Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},
journal = {International Journal of Advanced Computer Science and Applications},
doi = {10.14569/IJACSA.2021.0121177},
url = {http://dx.doi.org/10.14569/IJACSA.2021.0121177},
year = {2021},
publisher = {The Science and Information Organization},
volume = {12},
number = {11},
author = {Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto}
}

@InProceedings{Zhu_2021_CVPR,
    author    = {Zhu, Fengda and Liang, Xiwen and Zhu, Yi and Yu, Qizhi and Chang, Xiaojun and Liang, Xiaodan},
    title     = {SOON: Scenario Oriented Object Navigation With Graph-Based Exploration},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {12689-12699}
}

@InProceedings{10.1007/978-3-031-73397-0_3,
author="Kong, Xianghao
and Chen, Jinyu
and Wang, Wenguan
and Su, Hang
and Hu, Xiaolin
and Yang, Yi
and Liu, Si",
editor="Leonardis, Ale{\v{s}}
and Ricci, Elisa
and Roth, Stefan
and Russakovsky, Olga
and Sattler, Torsten
and Varol, G{\"u}l",
title="Controllable Navigation Instruction Generation with Chain of Thought Prompting",
booktitle="Computer Vision -- ECCV 2024",
year="2025",
publisher="Springer Nature Switzerland",
address="Cham",
pages="37--54",
abstract="Instruction generation is a vital and multidisciplinary research area with broad applications. Existing instruction generation models are limited to generating instructions in a single style from a particular dataset, and the style and content of generated instructions cannot be controlled. Moreover, most existing instruction generation methods also disregard the spatial modeling of the navigation environment. Leveraging the capabilities of Large Language Models (LLMs), we propose C-Instructor, which utilizes the chain-of-thought-style prompt for style-controllable and content-controllable instruction generation. Firstly, we propose a Chain of Thought with Landmarks (CoTL) mechanism, which guides the LLM to identify key landmarks and then generate complete instructions. CoTL renders generated instructions more accessible to follow and offers greater controllability over the manipulation of landmark objects. Furthermore, we present a Spatial Topology Modeling Task to facilitate the understanding of the spatial structure of the environment. Finally, we introduce a Style-Mixed Training policy, harnessing the prior knowledge of LLMs to enable style control for instruction generation based on different prompts within a single model instance. Extensive experiments demonstrate that instructions generated by C-Instructor outperform those generated by previous methods in text metrics, navigation guidance evaluation, and user studies.",
isbn="978-3-031-73397-0"
}

@inproceedings{wang-etal-2024-navigating,
    title = "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation",
    author = "Wang, Zehao  and
      Wu, Minye  and
      Cao, Yixin  and
      Ma, Yubo  and
      Chen, Meiqi  and
      Tuytelaars, Tinne",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.269/",
    doi = "10.18653/v1/2024.findings-emnlp.269",
    pages = "4681--4704",
    abstract = "This study presents a novel evaluation framework for the Vision-Language Navigation (VLN) task. It aims to diagnose current models for various instruction categories at a finer-grained level. The framework is structured around the context-free grammar (CFG) of the task. The CFG serves as the basis for the problem decomposition and the core premise of the instruction categories design. We propose a semi-automatic method for CFG construction with the help of Large-Language Models (LLMs). Then, we induct and generate data spanning five principal instruction categories (i.e. direction change, landmark recognition, region recognition, vertical movement, and numerical comprehension). Our analysis of different models reveals notable performance discrepancies and recurrent issues. The stagnation of numerical comprehension, heavy selective biases over directional concepts, and other interesting findings contribute to the development of future language-guided navigation systems. The project is now available at https://zehao-wang.github.io/navnuances."
}

@inproceedings{mondal-etal-2022-cocoa,
    title = "{C}o{C}oa: An Encoder-Decoder Model for Controllable Code-switched Generation",
    author = "Mondal, Sneha  and
      Ritika.  and
      Pathak, Shreya  and
      Jyothi, Preethi  and
      Raghuveer, Aravindan",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.158/",
    doi = "10.18653/v1/2022.emnlp-main.158",
    pages = "2466--2479",
    abstract = "Code-switching has seen growing interest in recent years as an important multilingual NLP phenomenon. Generating code-switched text for data augmentation has been sufficiently well-explored. However, there is no prior work on generating code-switched text with fine-grained control on the degree of code-switching and the lexical choices used to convey formality. We present CoCoa, an encoder-decoder translation model that converts monolingual Hindi text to Hindi-English code-switched text with both encoder-side and decoder-side interventions to achieve fine-grained controllable generation. CoCoa can be invoked at test-time to synthesize code-switched text that is simultaneously faithful to syntactic and lexical attributes relevant to code-switching. CoCoa outputs were subjected to rigorous subjective and objective evaluations. Human evaluations establish that our outputs are of superior quality while being faithful to desired attributes. We show significantly improved BLEU scores when compared with human-generated code-switched references. Compared to competitive baselines, we show 10{\%} reduction in perplexity on a language modeling task and also demonstrate clear improvements on a downstream code-switched sentiment analysis task."
}

@article{DBLP:journals/access/HidayatullahQLA22,
  author  = {Ahmad Fathan Hidayatullah and Atika Qazi and Daphne Teck Ching Lai and Rosyzie Anna Apong},
  title   = {A Systematic Review on Language Identification of Code-Mixed Text: Techniques, Data Availability, Challenges, and Framework Development},
  journal = {{IEEE} Access},
  volume  = {10},
  pages   = {122812--122831},
  year    = {2022},
  url     = {https://doi.org/10.1109/ACCESS.2022.3223703},
  doi     = {10.1109/ACCESS.2022.3223703}
}

@article{HidayatullahPLM2025,
  author = {Hidayatullah, Ahmad Fathan and Apong, Rosyzie Anna and Lai, Daphne Teck Ching and Qazi, Atika},
  title = {Pre-trained language model for code-mixed text in Indonesian, Javanese, and English using transformer},
  journal = {Social Network Analysis and Mining},
  year = {2025},
  month = mar,
  volume = {15},
  number = {1},
  pages = {30},
  doi = {10.1007/s13278-025-01444-9},
  url = {https://doi.org/10.1007/s13278-025-01444-9},
  issn = {1869-5469},
  date = {2025-03-28},
  abstract = {Pre-trained language models (PLMs) have become increasingly pop... adapt to a broader range of code-mixed languages and dialects.}
}

@article{lavi-rotbain2022learnability,
title = {The learnability consequences of Zipfian distributions in language},
journal = {Cognition},
volume = {223},
pages = {105038},
year = {2022},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2022.105038},
url = {https://www.sciencedirect.com/science/article/pii/S0010027722000269},
author = {Ori Lavi-Rotbain and Inbal Arnon},
keywords = {Language acquisition, Distributional learning, Information theory, Zipf's law, Word segmentation},
abstract = {While the languages of the world differ in many respects, they share certain commonalties, which can provide insight on our shared cognition. Here, we explore the learnability consequences of one of the striking commonalities between languages. Across languages, word frequencies follow a Zipfian distribution, showing a power law relation between a word's frequency and its rank. While their source in language has been studied extensively, less work has explored the learnability consequences of such distributions for language learners. We propose that the greater predictability of words in this distribution (relative to less skewed distributions) can facilitate word segmentation, a crucial aspect of early language acquisition. To explore this, we quantify word predictability using unigram entropy, assess it across languages using naturalistic corpora of child-directed speech and then ask whether similar unigram predictability facilitates word segmentation in the lab. We find similar unigram entropy in child-directed speech across 15 languages. We then use an auditory word segmentation task to show that the unigram predictability levels found in natural language are uniquely facilitative for word segmentation for both children and adults. These findings illustrate the facilitative impact of skewed input distributions on learning and raise questions about the possible role of cognitive pressures in the prevalence of Zipfian distributions in language.}
}

@inproceedings{mikhaylovskiy-2025-zipfs,
    title = "{Z}ipf{'}s and Heaps' Laws for Tokens and {LLM}-generated Texts",
    author = "Mikhaylovskiy, Nikolay",
    editor = "Christodoulopoulos, Christos  and
      Chakraborty, Tanmoy  and
      Rose, Carolyn  and
      Peng, Violet",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2025",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-emnlp.837/",
    doi = "10.18653/v1/2025.findings-emnlp.837",
    pages = "15469--15481",
    ISBN = "979-8-89176-335-7",
    abstract = "The frequency distribution of words in human-written texts roughly follows a simple mathematical form known as Zipf{'}s law. Somewhat less well known is the related Heaps' law, which describes a sublinear power-law growth of vocabulary size with document size. We study the applicability of Zipf{'}s and Heaps' laws to texts generated by Large Language Models (LLMs). We empirically show that Heaps' and Zipf{'}s laws only hold for LLM-generated texts in a narrow model-dependent temperature range. These temperatures have an optimal value close to $t=1$ for all the base models except the large Llama models, are higher for instruction-finetuned models and do not depend on the model size or prompting. This independently confirms the recent discovery of sampling temperature dependent phase transitions in LLM-generated texts."
}

@inproceedings{yokoi2024zipfian,
 author = {Yokoi, Sho and Bao, Han and Kurita, Hiroto and Shimodaira, Hidetoshi},
 booktitle = {Advances in Neural Information Processing Systems},
 doi = {10.52202/079017-3885},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {122259--122291},
 publisher = {Curran Associates, Inc.},
 title = {Zipfian Whitening},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/dd1fef536655685898a6602bfbf16857-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}

@inproceedings{kawintiranon-singh-2021-knowledge,
    title = "Knowledge Enhanced Masked Language Model for Stance Detection",
    author = "Kawintiranon, Kornraphop  and
      Singh, Lisa",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.376/",
    doi = "10.18653/v1/2021.naacl-main.376",
    pages = "4725--4735",
    abstract = "Detecting stance on Twitter is especially challenging because of the short length of each tweet, the continuous coinage of new terminology and hashtags, and the deviation of sentence structure from standard prose. Fine-tuned language models using large-scale in-domain data have been shown to be the new state-of-the-art for many NLP tasks, including stance detection. In this paper, we propose a novel BERT-based fine-tuning method that enhances the masked language model for stance detection. Instead of random token masking, we propose using a weighted log-odds-ratio to identify words with high stance distinguishability and then model an attention mechanism that focuses on these words. We show that our proposed approach outperforms the state of the art for stance detection on Twitter data about the 2020 US Presidential election."
}

@inproceedings{ye-etal-2021-towards,
    title = "Towards More Fine-grained and Reliable {NLP} Performance Prediction",
    author = "Ye, Zihuiwen  and
      Liu, Pengfei  and
      Fu, Jinlan  and
      Neubig, Graham",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.324/",
    doi = "10.18653/v1/2021.eacl-main.324",
    pages = "3703--3714",
    abstract = "Performance prediction, the task of estimating a system{'}s performance without performing experiments, allows us to reduce the experimental burden caused by the combinatorial explosion of different datasets, languages, tasks, and models. In this paper, we make two contributions to improving performance prediction for NLP tasks. First, we examine performance predictors not only for holistic measures of accuracy like F1 or BLEU, but also \textit{fine-grained} performance measures such as accuracy over individual classes of examples. Second, we propose methods to understand the \textit{reliability} of a performance prediction model from two angles: confidence intervals and calibration. We perform an analysis of four types of NLP tasks, and both demonstrate the feasibility of fine-grained performance prediction and the necessity to perform reliability analysis for performance prediction methods in the future."
}

@inproceedings{pofcher-etal-2025-emnlp,
    title = "Hope vs. Hate: Understanding User Interactions with {LGBTQ}+ News Content in Mainstream {US} News Media through the Lens of Hope Speech",
    author = "Pofcher, Jonathan  and
      Homan, Christopher M  and
      Sell, Randall  and
      KhudaBukhsh, Ashiqur R.",
    editor = "Christodoulopoulos, Christos  and
      Chakraborty, Tanmoy  and
      Rose, Carolyn  and
      Peng, Violet",
    booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.emnlp-main.1005/",
    doi = "10.18653/v1/2025.emnlp-main.1005",
    pages = "19862--19888",
    ISBN = "979-8-89176-332-6",
    abstract = "This paper makes three contributions. First, via a substantial corpus of 1,419,047 comments posted on 3,161 YouTube news videos of major US cable news outlets, we analyze how users engage with LGBTQ+ news content. Our analyses focus both on positive and negative content. In particular, we construct a \textit{hope speech} classifier that detects positive (\textit{hope speech}), negative, neutral, and irrelevant content. Second, in consultation with a public health expert specializing on LGBTQ+ health, we conduct an annotation study with a balanced and diverse political representation and release a dataset of 3,750 instances with crowd-sourced labels and detailed annotator demographic information. Finally, beyond providing a vital resource for the LGBTQ+ community, our annotation study and subsequent in-the-wild assessments reveal (1) strong association between rater political beliefs and how they rate content relevant to a marginalized community, (2) models trained on individual political beliefs exhibit considerable in-the-wild disagreement, and (3) zero-shot large language models (LLMs) align more with liberal raters."
}

@inproceedings{Zhu2022DiagnosingVLN,
    title = "Diagnosing Vision-and-Language Navigation: What Really Matters",
    author = "Zhu, Wanrong  and
      Qi, Yuankai  and
      Narayana, Pradyumna  and
      Sone, Kazoo  and
      Basu, Sugato  and
      Wang, Xin  and
      Wu, Qi  and
      Eckstein, Miguel  and
      Wang, William Yang",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.438/",
    doi = "10.18653/v1/2022.naacl-main.438",
    pages = "5981--5993",
    abstract = "Vision-and-language navigation (VLN) is a multimodal task where an agent follows natural language instructions and navigates in visual environments. Multiple setups have been proposed, and researchers apply new model architectures or training techniques to boost navigation performance. However, there still exist non-negligible gaps between machines' performance and human benchmarks. Moreover, the agents' inner mechanisms for navigation decisions remain unclear. To the best of our knowledge, how the agents perceive the multimodal input is under-studied and needs investigation. In this work, we conduct a series of diagnostic experiments to unveil agents' focus during navigation. Results show that indoor navigation agents refer to both object and direction tokens when making decisions. In contrast, outdoor navigation agents heavily rely on direction tokens and poorly understand the object tokens. Transformer-based agents acquire a better cross-modal understanding of objects and display strong numerical reasoning ability than non-Transformer-based agents. When it comes to vision-and-language alignments, many models claim that they can align object tokens with specific visual targets. We find unbalanced attention on the vision and text input and doubt the reliability of such cross-modal alignments."
}

@article{Skeppstedt2024WordRain,
author = {Maria Skeppstedt and Magnus Ahltorp and Kostiantyn Kucher and Matts Lindström},
title ={From word clouds to Word Rain: Revisiting the classic word cloud to visualize climate change texts},

journal = {Information Visualization},
volume = {23},
number = {3},
pages = {217-238},
year = {2024},
doi = {10.1177/14738716241236188},

URL = { 
    
        https://doi.org/10.1177/14738716241236188
    
    

},
eprint = { 
    
        https://doi.org/10.1177/14738716241236188
    
    

}
,
    abstract = { Word Rain is a development of the classic word cloud. It addresses some of the limitations of word clouds, in particular the lack of a semantically motivated positioning of the words, and the use of font size as a sole indicator of word prominence. Word Rain uses the semantic information encoded in a distributional semantics-based language model – reduced into one dimension – to position the words along the x-axis. Thereby, the horizontal positioning of the words reflects semantic similarity. Font size is still used to signal word prominence, but this signal is supplemented with a bar chart, as well as with the position of the words on the y-axis. We exemplify the use of Word Rain by three concrete visualization tasks, applied on different real-world texts and document collections on climate change. In these case studies, word2vec models, reduced to one dimension with t-SNE, are used to encode semantic similarity, and TF-IDF is used for measuring word prominence. We evaluate the technique further by carrying out domain expert reviews. }
}

@article{benShachar2024outliers,
  author  = {Ben-Shachar, Mattan S. and Patil, Indrajeet and L{\"u}decke, Daniel and Wiernik, Brenton M. and Makowski, Dominique},
  title   = {Check Your Outliers! An Introduction to Identifying Statistical Outliers in {R}},
  journal = {Behavior Research Methods},
  year    = {2024},
  doi     = {10.3758/s13428-024-02356-w},
  url     = {https://link.springer.com/article/10.3758/s13428-024-02356-w}
}

@incollection{henze2024edf,
  author    = {Henze, Norbert},
  title     = {Empirical Distribution Function},
  booktitle = {Asymptotic Stochastics},
  series    = {Mathematics Study Resources},
  volume    = {10},
  pages     = {95--102},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  year      = {2024},
  doi       = {10.1007/978-3-662-68923-3_7},
  url       = {https://link.springer.com/chapter/10.1007/978-3-662-68923-3_7}
}

@inproceedings{cohen2024rlg,
author = {Cohen, Vanya and Liu, Jason Xinyu and Mooney, Raymond and Tellex, Stefanie and Watkins, David},
title = {A survey of robotic language grounding: tradeoffs between symbols and embeddings},
year = {2024},
isbn = {978-1-956792-04-1},
url = {https://doi.org/10.24963/ijcai.2024/885},
doi = {10.24963/ijcai.2024/885},
abstract = {With large language models, robots can understand language more flexibly and more capable than ever before. This survey reviews and situates recent literature into a spectrum with two poles: 1) mapping between language and some manually defined formal representation of meaning, and 2) mapping between language and high-dimensional vector spaces that translate directly to low-level robot policy. Using a formal representation allows the meaning of the language to be precisely represented, limits the size of the learning problem, and leads to a framework for interpretability and formal safety guarantees. Methods that embed language and perceptual data into high-dimensional spaces avoid this manually specified symbolic structure and thus have the potential to be more general when fed enough data but require more data and computing to train. We discuss the benefits and tradeoffs of each approach and finish by providing directions for future work that achieves the best of both worlds.},
booktitle = {Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence},
articleno = {885},
numpages = {11},
location = {Jeju, Korea},
series = {IJCAI '24}
}

@inproceedings{shin2024semgro,
    title = "Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments",
    author = "Shin, Sangwoo  and
      Kim, SeungHyun  and
      Jang, Youngsoo  and
      Lee, Moontae  and
      Woo, Honguk",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.200/",
    doi = "10.18653/v1/2024.findings-acl.200",
    pages = "3354--3376",
    abstract = "In embodied instruction-following (EIF), the integration of pretrained language models (LMs) as task planners emerges as a significant branch, where tasks are planned at the skill level by prompting LMs with pretrained skills and user instructions. However, grounding these pretrained skills in different domains remains challenging due to their intricate entanglement with the domain-specific knowledge. To address this challenge, we present a semantic skill grounding (SemGro) framework that leverages the hierarchical nature of semantic skills. SemGro recognizes the broad spectrum of these skills, ranging from short-horizon low-semantic skills that are universally applicable across domains to long-horizon rich-semantic skills that are highly specialized and tailored for particular domains. The framework employs an iterative skill decomposition approach, starting from the higher levels of semantic skill hierarchy and then moving downwards, so as to ground each planned skill to an executable level within the target domain. To do so, we use the reasoning capabilities of LMs for composing and decomposing semantic skills, as well as their multi-modal extension for assessing the skill feasibility in the target domain. Our experiments in the VirtualHome benchmark show the efficacy of SemGro in 300 cross-domain EIF scenarios."
}

@inproceedings{shi2024opex,
author = {Shi, Haochen and Sun, Zhiyuan and Yuan, Xingdi and C\^{o}t\'{e}, Marc-Alexandre and Liu, Bang},
title = {OPEx: A Large Language Model-Powered Framework for Embodied Instruction Following},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Embodied Instruction Following (EIF) is crucial for understanding natural language in a practical context, requiring agents to follow verbal instructions for complex tasks. Traditionally, EIF relies heavily on expert annotations for learning, which are costly and sometimes unattainable. Recent research shows Large Language Models (LLMs) can use their reasoning ability to help in EIF with minimal examples, but applying LLMs directly faces issues like hallucinations and partially observable environment. To bridge the gap, we introduce OPEx, a new LLM-based method for EIF that needs far less specific data. OPEx uses three LLMs for different roles: observing to gather environment data, planning by breaking down instructions, and executing tasks with learned skills. Our tests reveal OPEx significantly outperforms the FILM baseline, with 90\% less training data for planning tasks and achieving up to 38\% performance gain when FILM is trained on identical data.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {2465–2467},
numpages = {3},
keywords = {embodied instruction following, grounded planning, in context learning, language grounding, large language models},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{li2024eai,
 author = {Li, Manling and Zhao, Shiyu and Wang, Qineng and Wang, Kangrui and Zhou, Yu and Srivastava, Sanjana and Gokmen, Cem and Lee, Tony and Li, Li Erran and Zhang, Ruohan and Liu, Weiyu and Liang, Percy and Fei-Fei, Li and Mao, Jiayuan and Wu, Jiajun},
 booktitle = {Advances in Neural Information Processing Systems},
 doi = {10.52202/079017-3188},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {100428--100534},
 publisher = {Curran Associates, Inc.},
 title = {Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/b631da756d1573c24c9ba9c702fde5a9-Paper-Datasets_and_Benchmarks_Track.pdf},
 volume = {37},
 year = {2024}
}


@article{monWilliams2025ellmer,
  author  = {Mon-Williams, Ruaridh and Li, Gen and Long, Ran and Du, Wenqian and Lucas, Christopher G.},
  title   = {Embodied Large Language Models Enable Robots to Complete Complex Tasks in Unpredictable Environments},
  journal = {Nature Machine Intelligence},
  year    = {2025},
  volume  = {7},
  pages   = {592--601},
  doi     = {10.1038/s42256-025-01005-x},
  url     = {https://www.nature.com/articles/s42256-025-01005-x.pdf}
}

@inproceedings{deps2023neurips,
 author = {Wang, Zihao and Cai, Shaofei and Chen, Guanzhou and Liu, Anji and Ma, Xiaojian (Shawn) and Liang, Yitao},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {34153--34189},
 publisher = {Curran Associates, Inc.},
 title = {Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/6b8dfb8c0c12e6fafc6c256cb08a5ca7-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@inproceedings{egoplan2023neurips,
 author = {Liu, Xiatoian and Palacios, Hector and Muise, Christian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {54586--54613},
 publisher = {Curran Associates, Inc.},
 title = {Egocentric Planning for Scalable Embodied Task Achievement},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/ab0b1be09c317cb068aecfa7fa86a7e3-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{zhang2024msp_pms,
title = {A mission success probability assessment framework for phased-mission-systems using extended graphical evaluation and review technique},
journal = {Reliability Engineering \& System Safety},
volume = {249},
pages = {110248},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.110248},
url = {https://www.sciencedirect.com/science/article/pii/S095183202400320X},
author = {Jingru Zhang and Zhigeng Fang and Wenjie Dong and Sifeng Liu and Ding Chen},
keywords = {Phased-mission-system, Mission success probability assessment, Cascading effect, Extended graphical evaluation and review technique, Activity re-execution},
abstract = {Mission success probability (MSP) characterizes the capability of successfully completing the desired mission under external disruptions and internal failures, which is of great significance in assessing the availability of phased-mission-system (PMS). Therefore, in order to precisely resolve the MSP and analyze the PMS, a novel mission-driven four-level modular framework is established. Firstly, by dissecting and outlining missions from top to bottom, mission analysis implements multi-granularity analysis from abstract to concrete. The overall objective, sub-tasks, phased tasks, supported component and its configuration are all identified. Secondly, the general MSP assessment procedure is elaborated from the perspectives of operation level, phase level and mission level. Under the provided extended graphical evaluation and review technique (EGERT), the metrics of PMS are deduced from a single activity’s metrics while considering the cascading effect and time factor. Finally, the presented model is employed to illustrate how the MSP evaluation is carried out in a regional air defensive system of systems.}
}

@article{torrado2024series_parallel_dependent,
title = {Analyzing component failures in series-parallel systems with dependent components},
journal = {Computers \& Industrial Engineering},
volume = {197},
pages = {110604},
year = {2024},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2024.110604},
url = {https://www.sciencedirect.com/science/article/pii/S0360835224007253},
author = {Nuria Torrado and Murat Ozkut},
keywords = {Copulas, Series-parallel system, Optimal design, Reliability},
abstract = {This paper investigates a series-parallel system comprising N independent subsystems with interchangeable dependent components, a prevalent reliability structure in engineering and network design. The primary aim of this research is to derive the joint probability distribution of the number of failed components within these configurations, considering component dependence and varying distributions across subsystems. This approach reflects a more realistic scenario than previously explored in the literature. Initially, the analysis is conducted for systems with two subsystems and subsequently extended to encompass configurations with N subsystems. The study also evaluates key reliability metrics including the average number of failed components and the mean time to failure (MTTF) of the entire system, theoretically proving that the system’s MTTF increases with the number of components under certain sufficient conditions. In addition to probabilistic analysis, an optimization problem is addressed to determine the optimal allocation of components within each subsystem. The objective is to minimize the average cost associated with corrective maintenance, thereby enhancing the cost-effectiveness of system operation.}
}

@inproceedings{guertler2025splAtes,
title={Long-Horizon Planning with Predictable Skills},
author={Nico G{\"u}rtler and Georg Martius},
booktitle={Reinforcement Learning Conference},
year={2025},
url={https://openreview.net/forum?id=G8ybRSxO10}
}